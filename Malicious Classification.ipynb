{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "from sklearn import feature_selection\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn import preprocessing as prp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\goyal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#Reading Dataset into a dataframe\n",
    "#Malicious_data = pd.read_csv(\"C:\\Jupyter running\\Malicious.csv\", index_col=0) \n",
    "Malicious_data = pd.read_csv(\"C:\\Jupyter running\\DrDoS_DNS.csv\", index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 87)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing no of rows and columns of dataframe\n",
    "Malicious_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after splitting label:\n",
      " (1048575, 86)\n",
      "Label Dataframe shape after splitting label:\n",
      " (1048575,)\n"
     ]
    }
   ],
   "source": [
    "#Separating features and label \n",
    "Malicious_features = Malicious_data.copy()\n",
    "Malicious_labels = Malicious_features.pop('TrafficNature')\n",
    "print(\"Features Dataframe Shape after splitting label:\\n\",Malicious_features.shape)\n",
    "print(\"Label Dataframe shape after splitting label:\\n\",Malicious_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after Deleting columns with only 1 unique value:\n",
      " (1048575, 74)\n"
     ]
    }
   ],
   "source": [
    "# To get number of unique values\n",
    "counts=Malicious_features.nunique()\n",
    "#To delete the columns with only 1 unique value\n",
    "to_del=[i for i,v in enumerate(counts) if v==1]\n",
    "colname = Malicious_features.columns[to_del]\n",
    "Malicious_features.drop(colname, axis=1, inplace= True)\n",
    "print(\"Features Dataframe Shape after Deleting columns with only 1 unique value:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after Deleting columns with less variance:\n",
      " (1048575, 11)\n"
     ]
    }
   ],
   "source": [
    "#Deleting the columns with less variance\n",
    "to_del=[i for i,v in enumerate(Malicious_features.nunique()) if float(v)/Malicious_features.shape[0]* 100 < 1]\n",
    "colname = Malicious_features.columns[to_del]\n",
    "Malicious_features.drop(colname, axis=1, inplace= True)\n",
    "print(\"Features Dataframe Shape after Deleting columns with less variance:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after Deleting columns of object(string) datatype:\n",
      " (1048575, 10)\n"
     ]
    }
   ],
   "source": [
    "# Deleting columns of datatype object\n",
    "String_columns=Malicious_features.columns[Malicious_features.dtypes == 'object']\n",
    "Malicious_features.drop(String_columns,axis=1, inplace= True)\n",
    "print(\"Features Dataframe Shape after Deleting columns of object(string) datatype:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after Deleting columns with infinity values:\n",
      " (1048575, 8)\n"
     ]
    }
   ],
   "source": [
    "#Deleting columns with infinity values\n",
    "col_name = Malicious_features.columns.to_series()[np.isinf(Malicious_features).any()] \n",
    "Malicious_features.drop(columns=col_name, inplace=True)\n",
    "print(\"Features Dataframe Shape after Deleting columns with infinity values:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after selecting best 5 features:\n",
      " (1048575, 5)\n"
     ]
    }
   ],
   "source": [
    "#selecting top 20 features from the available features\n",
    "select=sklearn.feature_selection.SelectKBest(k=5)\n",
    "selected_features= select.fit(Malicious_features,Malicious_labels)\n",
    "indices_selected=selected_features.get_support(indices=True)\n",
    "colnames_selected = [Malicious_features.columns[i] for i in indices_selected]\n",
    "Malicious_features=Malicious_features[colnames_selected]\n",
    "print(\"Features Dataframe Shape after selecting best 5 features:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after developing features interaction:\n",
      " (1048575, 15)\n"
     ]
    }
   ],
   "source": [
    "#function to create feature interactions\n",
    "def add_interactions(df):\n",
    " combos= list(combinations(list(df.columns), 2))\n",
    " colnames = list(df.columns) + ['_'.join(x) for x in combos]\n",
    "#finding interaction level\n",
    " poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    " df=poly.fit_transform(df)\n",
    " df=pd.DataFrame(df)\n",
    " df.columns=colnames  \n",
    "#Removing interaction terms with all 0 values\n",
    " noint_indicies=[i for i, x in enumerate(list((df==0).all())) if x]\n",
    " df=df.drop(df.columns[noint_indicies], axis=1)\n",
    " return df \n",
    "#Calling add_interaction function\n",
    "Malicious_features= add_interactions(Malicious_features)\n",
    "print(\"Features Dataframe Shape after developing features interaction:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dataframe Shape after reducing dimentions to 10:\n",
      " (1048575, 10)\n"
     ]
    }
   ],
   "source": [
    "#Dimentionality reduction\n",
    "pca = PCA(n_components=10)\n",
    "Malicious_features = pd.DataFrame(pca.fit_transform(Malicious_features))\n",
    "print(\"Features Dataframe Shape after reducing dimentions to 10:\\n\",Malicious_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Training and Testing sets\n",
    "Malicious_features_train, Malicious_features_test, Malicious_labels_train, Malicious_labels_test = train_test_split(Malicious_features, Malicious_labels, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Training and Testing labels\n",
    "le= LabelEncoder()\n",
    "test= Malicious_labels_train.values\n",
    "le.fit(test)\n",
    "Malicious_labels_train=le.transform(test)\n",
    "\n",
    "le= LabelEncoder()\n",
    "test= Malicious_labels_test.values\n",
    "le.fit(test)\n",
    "Malicious_labels_test=le.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization \n",
    "normalize = preprocessing.Normalization()\n",
    "Malicious_features_train=np.array(Malicious_features_train)\n",
    "Malicious_features_test=np.array(Malicious_features_test)\n",
    "\n",
    "#Scalaing the data\n",
    "scale_1 =prp.MaxAbsScaler()\n",
    "Malicious_features_train = scale_1.fit_transform(Malicious_features_train)\n",
    "Malicious_features_test = scale_1.fit_transform(Malicious_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Malicious_features_train\n",
    "y=Malicious_labels_train\n",
    "X1=Malicious_features_test\n",
    "y1=Malicious_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.08      0.14       386\n",
      "           1       1.00      1.00      1.00    209329\n",
      "\n",
      "    accuracy                           1.00    209715\n",
      "   macro avg       0.97      0.54      0.57    209715\n",
      "weighted avg       1.00      1.00      1.00    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Different Machine learning Models\n",
    "# Logistic Regression\n",
    "LR = LogisticRegression(random_state=1, max_iter=100, multi_class=\"multinomial\").fit(X, y)\n",
    "Logistic_Result=LR.predict(X1)\n",
    "print(classification_report(y1, Logistic_Result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.11      0.20       386\n",
      "           1       1.00      1.00      1.00    209329\n",
      "\n",
      "    accuracy                           1.00    209715\n",
      "   macro avg       0.99      0.55      0.60    209715\n",
      "weighted avg       1.00      1.00      1.00    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X, y)\n",
    "SVM_Result=SVM.predict(X1)\n",
    "print(classification_report(y1, SVM_Result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.20      0.32       386\n",
      "           1       1.00      1.00      1.00    209329\n",
      "\n",
      "    accuracy                           1.00    209715\n",
      "   macro avg       0.91      0.60      0.66    209715\n",
      "weighted avg       1.00      1.00      1.00    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forets\n",
    "RF = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "RF.fit(X, y)\n",
    "RandonForest_Result=RF.predict(X1)\n",
    "print(classification_report(y1, RandonForest_Result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.13      0.24       386\n",
      "           1       1.00      1.00      1.00    209329\n",
      "\n",
      "    accuracy                           1.00    209715\n",
      "   macro avg       0.97      0.57      0.62    209715\n",
      "weighted avg       1.00      1.00      1.00    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Network alpha=1e-5 random_state=1\n",
    "NN = MLPClassifier(solver='adam', hidden_layer_sizes=(5, 2))\n",
    "NN.fit(X, y)\n",
    "Neural_Netwrok_Result=NN.predict(X1)\n",
    "print(classification_report(y1, Neural_Netwrok_Result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
